{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Production Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# Import this weeks LinearModels .py file\n",
    "import LinearModels_assign as lm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('firms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_array = np.array(dat)\n",
    "\n",
    "id_array = dat_array[:, 0]\n",
    "\n",
    "# Count how many persons we have. This returns a tuple with the unique IDs,\n",
    "# and the number of times each person is observed.\n",
    "unique_id = np.unique(id_array, return_counts=True)\n",
    "n = unique_id[0].size\n",
    "t = int(unique_id[1].mean())\n",
    "year = np.array(dat_array[:, 1], dtype=int)\n",
    "\n",
    "# Load the rest of the data into arrays.\n",
    "y = dat_array[:,4].reshape(-1,1)\n",
    "x = np.column_stack(( np.ones(y.shape[0]), dat_array[:,2:4]))\n",
    "\n",
    "# Labels\n",
    "# Lets also make some variable names\n",
    "label_y = 'ldsa'\n",
    "label_x = [\n",
    "    'Constant', \n",
    "    'lcap', \n",
    "    'lemp', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the model with pooled OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: ldsa\n",
      "\n",
      "            Beta      Se    t-values\n",
      "--------  ------  ------  ----------\n",
      "Constant  0.0000  0.0161      0.0000\n",
      "lcap      0.3100  0.0324      9.5810\n",
      "lemp      0.6748  0.0366     18.4526\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "ols_result = lm.estimate(y, x, robust_se=True, t=t, n=n)\n",
    "lm.print_table(\n",
    "    (label_y, label_x), ols_result, title=\"Pooled OLS\", floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating a fixed effects (FE) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demeaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demeaning_matrix(t):\n",
    "    Q_T = np.eye(t) - np.tile(1/t, (t, t))\n",
    "    return Q_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_T = demeaning_matrix(t)\n",
    "y_demean = lm.perm(Q_T, y)\n",
    "x_demean = lm.perm(Q_T, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of x: 2\n",
      "Eigenvalues of within-transformed x: [  0.  58. 214.]\n"
     ]
    }
   ],
   "source": [
    "# Check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "check_rank(x_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant is constant over time and therefore has to be removed before using the FE estimator. (x has to be of full rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_demean = x_demean[:,1:]\n",
    "label_x_fe = label_x[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the FE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE regression\n",
      "Dependent variable: ldsa\n",
      "\n",
      "        Beta      Se    t-values\n",
      "----  ------  ------  ----------\n",
      "lcap  0.1546  0.0299      5.1630\n",
      "lemp  0.6942  0.0417     16.6674\n",
      "R² = 0.477\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fe_result = lm.estimate(\n",
    "    y_demean, x_demean, transform='fe', robust_se=True, t=t, n=n\n",
    ")\n",
    "lm.print_table(\n",
    "    (label_y, label_x_fe), \n",
    "    fe_result, title='FE regression', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating a first differences (FD) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data, taking first differences of y and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_matrix(t):\n",
    "    D_T = np.eye(t) - np.eye(t, k=-1)\n",
    "    D_T = D_T[1:]\n",
    "    return D_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data.\n",
    "D_T = fd_matrix(t)\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of x: 2\n",
      "Eigenvalues of within-transformed x: [47. 35.  0.]\n"
     ]
    }
   ],
   "source": [
    "check_rank(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we remove the constant as our x_diff is not of full rank\n",
    "x_diff = x_diff[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the FD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD regression\n",
      "Dependent variable: ldsa\n",
      "\n",
      "        Beta      Se    t-values\n",
      "----  ------  ------  ----------\n",
      "lcap  0.0630  0.0191      3.3043\n",
      "lemp  0.5487  0.0183     29.9635\n",
      "R² = 0.165\n",
      "σ² = 0.014\n"
     ]
    }
   ],
   "source": [
    "fd_result = lm.estimate(\n",
    "    y_diff, x_diff, robust_se=True, t=t, n=n\n",
    ")\n",
    "lm.print_table(\n",
    "    (label_y, label_x_fe), \n",
    "    fd_result, title='FD regression', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating a random effects (RE) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quasi-demeaning the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the mean matrix $P_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_matrix(t):\n",
    "    P_T = np.tile(1/t, (t, t))\n",
    "    return P_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data.\n",
    "P_T = mean_matrix(t)\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check rank of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of x: 3\n",
      "Eigenvalues of within-transformed x: [ 5292. 15515.   675.]\n"
     ]
    }
   ],
   "source": [
    "check_rank(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix is of full rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now estimate using the between estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: ldsa\n",
      "\n",
      "            Beta      Se    t-values\n",
      "--------  ------  ------  ----------\n",
      "Constant  0.0000  0.0046      0.0000\n",
      "lcap      0.3188  0.0089     35.8720\n",
      "lemp      0.6672  0.0099     67.6130\n",
      "R² = 0.923\n",
      "σ² = 0.114\n"
     ]
    }
   ],
   "source": [
    "be_result = lm.estimate(y_mean, x_mean, robust_se=False, t=t, n=n)\n",
    "lm.print_table(\n",
    "    (label_y, label_x), be_result, title=\"Pooled OLS\", floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now estimate $\\hat \\lambda$ using $\\hat{\\sigma}_u ^2$ and $\\hat{\\sigma}_c ^2$:\n",
    "\n",
    "$$\\hat{\\lambda} = 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{(\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2})}}, $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_FE = fe_result[\"sigma\"][0][0]\n",
    "sigma_BE = be_result[\"sigma\"][0][0] - sigma_FE/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 1 - np.sqrt(sigma_FE/(sigma_FE + t*sigma_BE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using $\\lambda$ we now quasi demean our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_matrix(t):\n",
    "    Q_T = np.eye(t) - np.tile(lamb*1/t, (t, t))\n",
    "    return Q_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_t = quasi_matrix(t)\n",
    "y_quasi = lm.perm(Q_t, y)\n",
    "x_quasi = lm.perm(Q_t, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of x: 3\n",
      "Eigenvalues of within-transformed x: [ 68. 412.  67.]\n"
     ]
    }
   ],
   "source": [
    "check_rank(x_quasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating quasi demeaned variables using POLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: ldsa\n",
      "\n",
      "            Beta      Se    t-values\n",
      "--------  ------  ------  ----------\n",
      "Constant  0.0000  0.0162      0.0000\n",
      "lcap      0.1990  0.0117     17.0431\n",
      "lemp      0.7197  0.0131     54.8444\n",
      "R² = 0.643\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "re_result = lm.estimate(y_quasi, x_quasi, transform = \"re\", robust_se=False, t=t, n=n)\n",
    "lm.print_table(\n",
    "    (label_y, label_x), re_result, title=\"Pooled OLS\", floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hausman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Follow the steps in the question\n",
    "# Calculate without Robust SE!\n",
    "hat_diff =  fe_result['b_hat'] - re_result[\"b_hat\"][1:]\n",
    "cov_diff =  fe_result['cov'] - re_result['cov'][1:,1:]\n",
    "H =  hat_diff.T @ la.inv(cov_diff) @ hat_diff\n",
    "\n",
    "# This calculates the p-value of the Hausman test.\n",
    "p_val = chi2.sf(H.item(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  b_fe    b_re    b_diff\n",
      "------  ------  --------\n",
      "0.1546  0.1990   -0.0444\n",
      "0.6942  0.7197   -0.0255\n",
      "The Hausman test statistic is: 73.87, with p-value: 0.00.\n"
     ]
    }
   ],
   "source": [
    "# This code takes the results that you have made, and prints a nice looking table.\n",
    "def print_h_test(fe_result, re_result, hat_diff, p_val):\n",
    "    table = []\n",
    "    for i in range(len(hat_diff)):\n",
    "        row = [\n",
    "            fe_result['b_hat'][i], re_result['b_hat'][1:][i], hat_diff[i]\n",
    "        ]\n",
    "        table.append(row)\n",
    "\n",
    "    print(tabulate(\n",
    "        table, headers=['b_fe', 'b_re', 'b_diff'], floatfmt='.4f'\n",
    "        ))\n",
    "    print(f'The Hausman test statistic is: {H.item():.2f}, with p-value: {p_val:.2f}.')\n",
    "print_h_test(fe_result, re_result, hat_diff, p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting the Hausman test using wald statistic implies that RE.3 holds. This might not be the case. Therefore, we use bootstrap, thereby not relying on assumptions on homoscedasticity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function for sub samples\n",
    "def hat_cov_diff(x,y,t,n):\n",
    "    \n",
    "    # estimate FE and RE regression on subsample\n",
    "    N,K = x.shape\n",
    "    \n",
    "    # FE\n",
    "    # demean\n",
    "    Q_T_i = demeaning_matrix(t)\n",
    "    y_demean_i = lm.perm(Q_T, y)\n",
    "    x_demean_i = lm.perm(Q_T, x)\n",
    "    #rank and remove if not full rank\n",
    "    x_demean_i = x_demean_i[:,K-la.matrix_rank(x_demean_i):]\n",
    "    # estimate\n",
    "    fe_result_i = lm.estimate(\n",
    "    y_demean_i, x_demean_i, transform='fe', t=t, n=n\n",
    "    )\n",
    "    \n",
    "    # RE\n",
    "    # between estimator\n",
    "    P_T_i = mean_matrix(t)\n",
    "    y_mean_i = lm.perm(P_T_i, y)\n",
    "    x_mean_i = lm.perm(P_T_i, x)\n",
    "    # rank\n",
    "    x_demean_i = x_mean_i[:,K-la.matrix_rank(x_mean_i):]\n",
    "    be_result_i = lm.estimate(y_mean_i, x_mean_i, t=t, n=n)\n",
    "    #Lambda\n",
    "    sigma_FE_i = fe_result_i[\"sigma\"][0][0]\n",
    "    sigma_BE_i = be_result_i[\"sigma\"][0][0] - sigma_FE/t\n",
    "    lamb = 1 - np.sqrt(sigma_FE_i/(sigma_FE_i + t*sigma_BE_i))\n",
    "    # quasi demean\n",
    "    Q_t_i = quasi_matrix(t)\n",
    "    y_quasi_i = lm.perm(Q_t_i, y)\n",
    "    x_quasi_i = lm.perm(Q_t_i, x)\n",
    "    # rank\n",
    "    x_quasi_i = x_quasi_i[:,K-la.matrix_rank(x_mean_i):]\n",
    "    re_result_i = lm.estimate(y_quasi_i, x_quasi_i, transform = \"re\", t=t, n=n)\n",
    "    \n",
    "    # Estimate Hausman statistic\n",
    "    hat_diff_lcap =  fe_result_i['b_hat'][0] - re_result_i[\"b_hat\"][1]\n",
    "    hat_diff_lemp =  fe_result_i['b_hat'][1] - re_result_i[\"b_hat\"][2]\n",
    "    hatt_diff = fe_result_i['b_hat'] - re_result_i[\"b_hat\"][1:]\n",
    "    \n",
    "    return hat_diff_lcap, hat_diff_lemp, hatt_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing bootsrap sample\n",
    "def bootstrap_sample(dat,n):\n",
    "    ii_boot = np.random.choice(range(1,n), n, replace=True)\n",
    "    new_df = dat.loc[dat['firmid'].isin(ii_boot)]\n",
    "    \n",
    "    # Set up function for sub samples\n",
    "\n",
    "    # We need to know the number of \n",
    "    dat_array = np.array(new_df)\n",
    "\n",
    "    id_array = dat_array[:, 0]\n",
    "\n",
    "    # Count how many persons we have. This returns a tuple with the unique IDs,\n",
    "    # and the number of times each person is observed.\n",
    "    unique_id = np.unique(id_array, return_counts=True)\n",
    "    n_i = unique_id[0].size\n",
    "    t_i = int(unique_id[1].mean())\n",
    "    year_i = np.array(dat_array[:, 1], dtype=int)\n",
    "\n",
    "    # Load the rest of the data into arrays.\n",
    "    y_i = dat_array[:,4].reshape(-1,1)\n",
    "    x_i = np.column_stack(( np.ones(y_i.shape[0]), dat_array[:,2:4]))\n",
    "    \n",
    "    return y_i, x_i, n_i, t_i, year_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap iteration 1/1000\n",
      "Bootstrap iteration 2/1000\n",
      "Bootstrap iteration 3/1000\n",
      "Bootstrap iteration 4/1000\n",
      "Bootstrap iteration 5/1000\n",
      "Bootstrap iteration 6/1000\n",
      "Bootstrap iteration 7/1000\n",
      "Bootstrap iteration 8/1000\n",
      "Bootstrap iteration 9/1000\n",
      "Bootstrap iteration 10/1000\n",
      "Bootstrap iteration 11/1000\n",
      "Bootstrap iteration 12/1000\n",
      "Bootstrap iteration 13/1000\n",
      "Bootstrap iteration 14/1000\n",
      "Bootstrap iteration 15/1000\n",
      "Bootstrap iteration 16/1000\n",
      "Bootstrap iteration 17/1000\n",
      "Bootstrap iteration 18/1000\n",
      "Bootstrap iteration 19/1000\n",
      "Bootstrap iteration 20/1000\n",
      "Bootstrap iteration 21/1000\n",
      "Bootstrap iteration 22/1000\n",
      "Bootstrap iteration 23/1000\n",
      "Bootstrap iteration 24/1000\n",
      "Bootstrap iteration 25/1000\n",
      "Bootstrap iteration 26/1000\n",
      "Bootstrap iteration 27/1000\n",
      "Bootstrap iteration 28/1000\n",
      "Bootstrap iteration 29/1000\n",
      "Bootstrap iteration 30/1000\n",
      "Bootstrap iteration 31/1000\n",
      "Bootstrap iteration 32/1000\n",
      "Bootstrap iteration 33/1000\n",
      "Bootstrap iteration 34/1000\n",
      "Bootstrap iteration 35/1000\n",
      "Bootstrap iteration 36/1000\n",
      "Bootstrap iteration 37/1000\n",
      "Bootstrap iteration 38/1000\n",
      "Bootstrap iteration 39/1000\n",
      "Bootstrap iteration 40/1000\n",
      "Bootstrap iteration 41/1000\n",
      "Bootstrap iteration 42/1000\n",
      "Bootstrap iteration 43/1000\n",
      "Bootstrap iteration 44/1000\n",
      "Bootstrap iteration 45/1000\n",
      "Bootstrap iteration 46/1000\n",
      "Bootstrap iteration 47/1000\n",
      "Bootstrap iteration 48/1000\n",
      "Bootstrap iteration 49/1000\n",
      "Bootstrap iteration 50/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9985a451b9b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# 2. estimate and compute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mhat_diff_lcap_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhat_diff_lemp_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhat_diff_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhat_cov_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# save for each iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-bca712fc79a9>\u001b[0m in \u001b[0;36mhat_cov_diff\u001b[1;34m(x, y, t, n)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mx_demean_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_mean_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mean_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mbe_result_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_mean_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mean_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;31m#Lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0msigma_FE_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfe_result_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sigma\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\JØ\\Advanced Microeconometrics\\Git_eksamen\\Assignments\\1\\LinearModels_assign.py\u001b[0m in \u001b[0;36mestimate\u001b[1;34m(y, x, transform, n, t, robust_se)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mb_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest_ols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mresid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mb_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mu_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresid\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mresid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mSSR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mresid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mSST\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run bootsrap procedure\n",
    "nboot = 1000  # Number of bootstraps, should ideally be very large \n",
    "\n",
    "# Set seed for random sampling.\n",
    "seed = 42\n",
    "rng = default_rng()\n",
    "\n",
    "# initialize \n",
    "hat_diff_o = np.empty((nboot,2,1))\n",
    "hat_diff_lcap_o = np.empty((nboot,1))\n",
    "hat_diff_lemp_o = np.empty((nboot,1))\n",
    "\n",
    "for i in range(nboot): \n",
    "    print(f'Bootstrap iteration {i+1}/{nboot}')\n",
    "    \n",
    "    # 1. draw sample from data \n",
    "    y_i, x_i, n_i, t_i, year_i = bootstrap_sample(dat,n)\n",
    "    \n",
    "    # 2. estimate and compute \n",
    "    hat_diff_lcap_0, hat_diff_lemp_0, hat_diff_0 = hat_cov_diff(x_i,y_i,t_i,n_i)\n",
    "    \n",
    "    # save for each iteration\n",
    "    hat_diff_o [i] = hat_diff_0\n",
    "    hat_diff_lcap_o [i] = hat_diff_lcap_0\n",
    "    hat_diff_lemp_o [i] = hat_diff_lemp_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_diff_boot = hat_diff_o.reshape(2,nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_diff_cov_boot = np.cov(hat_diff_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00013653, 0.00006335],\n",
       "       [0.00006335, 0.00014711]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_diff_cov_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hausman test using this statistic\n",
    "H_boot =  hat_diff.T @ la.inv(hat_diff_cov_boot) @ hat_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.65699423]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006565595783555797"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2.sf(H_boot.item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for serial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = int(x_diff.shape[0]/441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From exercises\n",
    "def serial_corr(y, x, year):\n",
    "    b_hat = lm.est_ols(y, x)\n",
    "    e = y - x@b_hat\n",
    "    \n",
    "    Lag_T = np.eye(tt-1,tt, k=0)\n",
    "    Lead_T = np.eye(tt-1,tt, k=1)\n",
    "    \n",
    "    e_l = lm.perm(Lag_T, e)\n",
    "    e = lm.perm(Lead_T,e)\n",
    "    \n",
    "    return lm.estimate(e_l, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Correlation\n",
      "Dependent variable: OLS residual, eᵢₜ\n",
      "\n",
      "          Beta      Se    t-values\n",
      "-----  -------  ------  ----------\n",
      "eᵢₜ₋₁  -0.1984  0.0148    -13.4493\n",
      "R² = 0.039\n",
      "σ² = 0.014\n"
     ]
    }
   ],
   "source": [
    "corr_result = serial_corr(y_diff, x_diff, tt)\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "title = 'Serial Correlation'\n",
    "\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result,\n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for strict exogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict exogeneity test\n",
      "Dependent variable: ldsa\n",
      "\n",
      "                    Beta      Se    t-values\n",
      "----------------  ------  ------  ----------\n",
      "lcap              0.0280  0.0348      0.8051\n",
      "lemp              0.5408  0.0381     14.1866\n",
      "Capital lead      0.1667  0.0424      3.9302\n",
      "Employement lead  0.1419  0.0263      5.4049\n",
      "R² = 0.478\n",
      "σ² = 0.016\n"
     ]
    }
   ],
   "source": [
    "# Create lead\n",
    "F_T = np.eye(t, k=1)\n",
    "F_T = F_T[:-1]\n",
    "\n",
    "# Lead Capital and Labour (employment)\n",
    "lcap_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n",
    "lemp_lead = lm.perm(F_T, x[:, 2].reshape(-1, 1))\n",
    "\n",
    "# Collect variables to test for exogeneity. We lead so we lose first observation\n",
    "x_exo = x[year != 1979]\n",
    "x_exo = np.hstack((x_exo, lcap_lead,lemp_lead))\n",
    "y_exo = y[year != 1979]\n",
    "\n",
    "# Make within transformation\n",
    "Q_T_exo = demeaning_matrix(t-1)\n",
    "y_demean_exo = lm.perm(Q_T_exo, y_exo)\n",
    "x_demean_exo = lm.perm(Q_T_exo, x_exo)\n",
    "x_demean_exo = x_demean_exo[:,1:]\n",
    "label_x_fe_exo = label_x[1:] + ['Capital lead'] + ['Employement lead']\n",
    "\n",
    "# Estimate FE model with the leaded variables\n",
    "fe_result_exo = lm.estimate(\n",
    "    y_demean_exo, x_demean_exo, transform='fe', robust_se=True, t=t, n=n\n",
    ")\n",
    "\n",
    "# Print table\n",
    "lm.print_table(\n",
    "    (label_y, label_x_fe_exo), \n",
    "    fe_result_exo, title='Strict exogeneity test', floatfmt='.4f'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the hypothesis lcap + lemp is = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([1,1])\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wald_test = (R @ fe_result['b_hat'] - r) / ( R @ fe_result['cov'] @ R.T) * (R @ fe_result['b_hat'] - r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.40291252])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wald_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\chi^2(1)$ distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_wald = chi2.sf(wald_test.item(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0584551670864466e-05\n"
     ]
    }
   ],
   "source": [
    "print(float(p_val_wald))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
